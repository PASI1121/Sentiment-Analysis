{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31a4760-e0c9-4b36-9b73-60a2a391484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49dc1e9d-575a-461b-a1a1-0c0114995473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'username': 'wpnabesinghe', 'key': '86777831f59069f20ceda38b43c88da8'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load a json file to following location\n",
    "with open ('../artifacts/kaggle.json','r') as file:\n",
    "    data=json.load(file)\n",
    "data  ##our authentigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b054f3-93d7-408c-858e-2b03c6c390de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kaggle\n",
      "  Using cached kaggle-1.6.17.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2.0.7)\n",
      "Requirement already satisfied: bleach in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105796 sha256=dc599a5637dd0774148a7ffc55c3c3b16d6e33b1d894279ca533e5449ba02c85\n",
      "  Stored in directory: c:\\users\\pasindu\\appdata\\local\\pip\\cache\\wheels\\ff\\55\\fb\\b27a466be754d2a06ffe0e37b248d844f090a63b51becea85d\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.6.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script kaggle.exe is installed in 'C:\\Users\\Pasindu\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc48049e-d588-4937-8108-94d82fbe985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME']=data['username']\n",
    "os.environ['KAGGLE_KEY']=data['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aee1656-c2e3-4f50-a919-e576c48bc2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect with kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api=KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c58189-c5cc-4b4d-babe-7d1af5109bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/dineshpiyasamara/sentiment-analysis-dataset\n"
     ]
    }
   ],
   "source": [
    "##Download the datasets through api\n",
    "api.dataset_download_files('dineshpiyasamara/sentiment-analysis-dataset',path='../artifacts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "421a06f4-707c-4753-8b63-9561c9cf33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract zip file\n",
    "import zipfile\n",
    "with zipfile.ZipFile('../artifacts/sentiment-analysis-dataset.zip','r') as zip_ref:\n",
    "    zip_ref.extractall('../artifacts/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da29243-1bc5-4a94-b133-9b695bb24646",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4151ea-af1b-4e26-afaf-953b37ce1aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>iPhone software update fucked up my phone big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Happy for us .. #instapic #instadaily #us #son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>New Type C charger cable #UK http://www.ebay.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Bout to go shopping again listening to music #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Photo: #fun #selfie #pool #water #sony #camera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to...\n",
       "5   6      1  iPhone software update fucked up my phone big ...\n",
       "6   7      0  Happy for us .. #instapic #instadaily #us #son...\n",
       "7   8      0  New Type C charger cable #UK http://www.ebay.c...\n",
       "8   9      0  Bout to go shopping again listening to music #...\n",
       "9  10      0  Photo: #fun #selfie #pool #water #sony #camera..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data =  pd.read_csv(\"../artifacts/sentiment_analysis.csv\")\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fea1447-5a7c-48b8-8187-c3d2247c494c",
   "metadata": {},
   "source": [
    "### Data reprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df20c60-9e8a-42cd-a908-7288f993d517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e28ec1a-f7ff-44d6-b0c1-91d9a43cf42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c06d1c4-c7d8-495c-92cb-247fbdb21c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    #fingerprint #pregnancy test https://goo.gl/h1...\n",
       "1    finally a transparant silicon case ^^ thanks t...\n",
       "2    we love this! would you go? #talk #makememorie...\n",
       "3    i'm wired i know i'm george i was made that wa...\n",
       "4    what amazing service! apple won't even talk to...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert tweet text data to lowercase text\n",
    "data['tweet'] = data['tweet'].str.lower()\n",
    "data['tweet'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "940eb7ce-49a0-4b70-ab99-887614451100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    #fingerprint #pregnancy test  #android #apps #...\n",
       "1    finally a transparant silicon case ^^ thanks t...\n",
       "2    we love this! would you go? #talk #makememorie...\n",
       "3    i'm wired i know i'm george i was made that wa...\n",
       "4    what amazing service! apple won't even talk to...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "url_pattern = r'http\\S+|www\\S+'\n",
    "\n",
    "# Remove URLs from the 'tweet' column\n",
    "data['tweet'] = data['tweet'].str.replace(url_pattern, '', regex=True)\n",
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a89c62c0-443a-4993-9ac2-04fe7cff8b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "372bf8f1-ccff-4f78-9ce1-3700fe89eb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnancy test  android apps beaut...\n",
       "1    finally a transparant silicon case  thanks to ...\n",
       "2    we love this would you go talk makememories un...\n",
       "3    im wired i know im george i was made that way ...\n",
       "4    what amazing service apple wont even talk to m...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation_pattern = r'[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]'\n",
    "import string\n",
    "# Remove punctuation from the 'tweet' column\n",
    "data['tweet'] = data['tweet'].str.replace(punctuation_pattern, '', regex=True)\n",
    "data['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be47850b-8bca-43de-b3af-ad1f3af8eede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnancy test  android apps beaut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>finally a transparant silicon case  thanks to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>we love this would you go talk makememories un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wired i know im george i was made that way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>what amazing service apple wont even talk to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>live out loud lol liveoutloud selfie smile son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>we would like to wish you an amazing day make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>helping my lovely 90 year old neighbor with he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>finally got my smart pocket wifi stay connecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>apple barcelona apple store bcn barcelona trav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "0        1      0  fingerprint pregnancy test  android apps beaut...\n",
       "1        2      0  finally a transparant silicon case  thanks to ...\n",
       "2        3      0  we love this would you go talk makememories un...\n",
       "3        4      0  im wired i know im george i was made that way ...\n",
       "4        5      1  what amazing service apple wont even talk to m...\n",
       "...    ...    ...                                                ...\n",
       "7915  7916      0  live out loud lol liveoutloud selfie smile son...\n",
       "7916  7917      0  we would like to wish you an amazing day make ...\n",
       "7917  7918      0  helping my lovely 90 year old neighbor with he...\n",
       "7918  7919      0  finally got my smart pocket wifi stay connecte...\n",
       "7919  7920      0  apple barcelona apple store bcn barcelona trav...\n",
       "\n",
       "[7920 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d045b07-6318-493d-81ad-cfe35e76d9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       fingerprint pregnancy test  android apps beaut...\n",
       "1       finally a transparant silicon case  thanks to ...\n",
       "2       we love this would you go talk makememories un...\n",
       "3       im wired i know im george i was made that way ...\n",
       "4       what amazing service apple wont even talk to m...\n",
       "                              ...                        \n",
       "7915    live out loud lol liveoutloud selfie smile son...\n",
       "7916    we would like to wish you an amazing day make ...\n",
       "7917    helping my lovely  year old neighbor with her ...\n",
       "7918    finally got my smart pocket wifi stay connecte...\n",
       "7919    apple barcelona apple store bcn barcelona trav...\n",
       "Name: tweet, Length: 7920, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_pattern = r'\\d+'\n",
    "\n",
    "# Remove numbers from the 'tweet' column\n",
    "data['tweet'] = data['tweet'].str.replace(number_pattern, '', regex=True)\n",
    "data['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc3a643c-421b-48f4-bc50-99509b35cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cde619e-6d7c-43bd-8173-3638f65994ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ../static/model...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords',download_dir='../static/model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ef4c1-212e-4b79-9db4-e4b629628ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f579d-2a48-4bd6-9488-aa2bde231611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83270aa8-89f5-4a56-bc7f-0d4a70c3d8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('../static/model/corpora/stopwords/english','r') as file:\n",
    "    sw = file.read().splitlines()\n",
    "\n",
    "sw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d7b9dc2-2c40-4938-a1cb-8572e2cbcbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       fingerprint pregnancy test android apps beauti...\n",
       "1       finally transparant silicon case thanks uncle ...\n",
       "2       love would go talk makememories unplug relax i...\n",
       "3       im wired know im george made way iphone cute d...\n",
       "4       amazing service apple wont even talk question ...\n",
       "                              ...                        \n",
       "7915    live loud lol liveoutloud selfie smile sony mu...\n",
       "7916    would like wish amazing day make every minute ...\n",
       "7917    helping lovely year old neighbor ipad morning ...\n",
       "7918    finally got smart pocket wifi stay connected a...\n",
       "7919    apple barcelona apple store bcn barcelona trav...\n",
       "Name: tweet, Length: 7920, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in sw]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "data['tweet'] = data['tweet'].apply(remove_stopwords)\n",
    "data['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1432a55-e9b3-45fa-8e27-4811894d6d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PorterStemmer>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e74c0dd7-2027-4f37-8ab5-fa2e57acc2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnanc test android app beauti c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>final transpar silicon case thank uncl yay son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>love would go talk makememori unplug relax iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wire know im georg made way iphon cute dave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>amaz servic appl wont even talk question unles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>live loud lol liveoutloud selfi smile soni mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>would like wish amaz day make everi minut coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>help love year old neighbor ipad morn made rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>final got smart pocket wifi stay connect anyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>appl barcelona appl store bcn barcelona travel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "0        1      0  fingerprint pregnanc test android app beauti c...\n",
       "1        2      0  final transpar silicon case thank uncl yay son...\n",
       "2        3      0  love would go talk makememori unplug relax iph...\n",
       "3        4      0  im wire know im georg made way iphon cute dave...\n",
       "4        5      1  amaz servic appl wont even talk question unles...\n",
       "...    ...    ...                                                ...\n",
       "7915  7916      0  live loud lol liveoutloud selfi smile soni mus...\n",
       "7916  7917      0  would like wish amaz day make everi minut coun...\n",
       "7917  7918      0  help love year old neighbor ipad morn made rea...\n",
       "7918  7919      0  final got smart pocket wifi stay connect anyti...\n",
       "7919  7920      0  appl barcelona appl store bcn barcelona travel...\n",
       "\n",
       "[7920 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Apply the function to the 'tweet' column\n",
    "data['tweet'] = data['tweet'].apply(preprocess_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5119c117-32da-40b2-b7d4-88341d87ee73",
   "metadata": {},
   "source": [
    "### Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28c5f7bd-2121-40ab-b6db-fa805da21436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "vocab=Counter()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77fc7a-4422-47c1-a42f-2881d0405fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be0026-07c0-40d5-bf53-64e0430546d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4bf421-1b6f-479f-9be8-b0187f9784e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in data['tweet']:\n",
    "    vocab.update(sentence.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b1a128e-fa79-4212-aecc-bb68a17e5b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15155"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9774120-ef6b-4bdb-b96d-df137f00fae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape  ## Feature = 15155 > records = 7920 , So overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef31714-78f0-43c4-aab4-a643273f0da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1e8f9-acf7-442e-8f7b-a9a5a6ecd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we select more than 10 times type words\n",
    "tokens = [key for key in vocab if vocab[key]>10]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "030d947f-c6d0-4b4e-aed3-7bc22843f37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1143"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8141d697-b284-48fc-b1d6-23dab35c77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_vocabulary(lines,filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file=open(filename,'w',encoding=\"utf-8\")\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "save_vocabulary(tokens,'../static/model/vocabulary.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d181cb-07ce-4cf1-a440-f8280c04f6a9",
   "metadata": {},
   "source": [
    "#### divide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3f945bb-484d-48ab-8ef0-8dcfa93471d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       fingerprint pregnanc test android app beauti c...\n",
       "1       final transpar silicon case thank uncl yay son...\n",
       "2       love would go talk makememori unplug relax iph...\n",
       "3       im wire know im georg made way iphon cute dave...\n",
       "4       amaz servic appl wont even talk question unles...\n",
       "                              ...                        \n",
       "7915    live loud lol liveoutloud selfi smile soni mus...\n",
       "7916    would like wish amaz day make everi minut coun...\n",
       "7917    help love year old neighbor ipad morn made rea...\n",
       "7918    final got smart pocket wifi stay connect anyti...\n",
       "7919    appl barcelona appl store bcn barcelona travel...\n",
       "Name: tweet, Length: 7920, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data['tweet']\n",
    "y=data['label']\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1aea7b35-9c15-49c2-958d-54b93bdd9092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "7915    0\n",
       "7916    0\n",
       "7917    0\n",
       "7918    0\n",
       "7919    0\n",
       "Name: label, Length: 7920, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88a78115-98ac-4ca4-a829-a3f4aba74af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fdc35d6-9e56-407e-9bef-b334b27b342c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6336,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "556b7332-1a94-4a8b-bf8c-974bcd43c32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1584,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80112e-3a0c-48af-b2f5-204765f78d2d",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a6c34617-7e2b-496b-9c2e-91e0d24e0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(ds,vocabulary):\n",
    "    vectorized_lst=[]\n",
    "    for sentence in ds:\n",
    "        sentence_lst = np.zeros(len(vocabulary))\n",
    "        for i in range(len(vocabulary)):\n",
    "            if vocabulary[i] in sentence.split():\n",
    "                sentence_lst[i] =1\n",
    "\n",
    "        vectorized_lst.append(sentence_lst)\n",
    "\n",
    "    vectorized_lst_new = np.asarray(vectorized_lst,dtype=np.float32)\n",
    "    return vectorized_lst_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3fdf0302-d61d-409e-b2b4-4ab36a60b3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_train=vectorizer(x_train,tokens)\n",
    "vectorized_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf4dd43d-64f9-468a-96cd-40f1de1ae29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_test=vectorizer(x_test,tokens)\n",
    "vectorized_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63abf3fd-0a89-4c17-8f8c-22f52bf80e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4731\n",
       "1    1605\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()  ## This is a unbalance data sets.I use smort test to balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ce21308-8fd6-4522-8c3a-704f39beea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Balance data set\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE()\n",
    "vectorized_x_train_smote,y_train_smote = smote.fit_resample(vectorized_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b4aeabdb-f6bd-4382-92a6-1522e0da19a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4731\n",
       "1    4731\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac701787-10f4-4e4b-b99d-50fad98b5fc3",
   "metadata": {},
   "source": [
    "## Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e3e61cec-59eb-4989-bd2d-d120be398652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from  sklearn.tree import DecisionTreeClassifier\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cd8fba34-d1a5-4ac2-a9c0-7b4c6d30d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "\n",
    "def training_scores(y_actu,y_pred):\n",
    "    acc=round(accuracy_score(y_actu,y_pred),3)\n",
    "    f1=round(f1_score(y_actu,y_pred),3)\n",
    "    pr=round(precision_score(y_actu,y_pred),3)\n",
    "    rec=round(recall_score(y_actu,y_pred),3)\n",
    "    print(f'training scores:\\n\\tAccuracy = {acc}\\n\\tf1_score={f1}\\n\\tPrecision={pr}\\n\\t\\Recall={rec}')\n",
    "\n",
    "def validation_scores(y_actu,y_pred):\n",
    "    acc=round(accuracy_score(y_actu,y_pred),3)\n",
    "    f1=round(f1_score(y_actu,y_pred),3)\n",
    "    pr=round(precision_score(y_actu,y_pred),3)\n",
    "    rec=round(recall_score(y_actu,y_pred),3)\n",
    "    print(f'training scores:\\n\\tAccuracy = {acc}\\n\\tf1_score={f1}\\n\\tPrecision={pr}\\n\\t\\Recall={rec}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf59865-e97f-4fa1-aea6-039dedbf8808",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "509047a7-f04c-4c5e-b6cb-f326da80f794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training scores:\n",
      "\tAccuracy = 0.939\n",
      "\tf1_score=0.94\n",
      "\tPrecision=0.914\n",
      "\t\\Recall=0.968\n",
      "training scores:\n",
      "\tAccuracy = 0.869\n",
      "\tf1_score=0.779\n",
      "\tPrecision=0.708\n",
      "\t\\Recall=0.865\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred = lr.predict(vectorized_x_train_smote)\n",
    "y_test_pred = lr.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831bf3f-13e3-479e-b135-97ce6fdcbc3a",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64107a0-4a25-4923-8150-bcad10828626",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred = lr.predict(vectorized_x_train_smote)\n",
    "y_test_pred = lr.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ec3d2-234f-402b-ac4c-15a9c72e4f91",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02e49cc5-7116-44eb-b8f6-5351ddadac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training scores:\n",
      "\tAccuracy = 0.907\n",
      "\tf1_score=0.911\n",
      "\tPrecision=0.868\n",
      "\t\\Recall=0.958\n",
      "training scores:\n",
      "\tAccuracy = 0.872\n",
      "\tf1_score=0.793\n",
      "\tPrecision=0.697\n",
      "\t\\Recall=0.922\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred = mnb.predict(vectorized_x_train_smote)\n",
    "y_test_pred = mnb.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a9290-4d47-46fa-9ce4-3433b730ab64",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "deb98197-3416-4865-8d6a-7f3ff97b4c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training scores:\n",
      "\tAccuracy = 1.0\n",
      "\tf1_score=1.0\n",
      "\tPrecision=1.0\n",
      "\t\\Recall=1.0\n",
      "training scores:\n",
      "\tAccuracy = 0.833\n",
      "\tf1_score=0.682\n",
      "\tPrecision=0.689\n",
      "\t\\Recall=0.675\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred = dt.predict(vectorized_x_train_smote)\n",
    "y_test_pred = dt.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932419e4-6f33-4992-b750-55867687221f",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "57d12e1d-f0c1-4ef2-b94e-27407f252f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training scores:\n",
      "\tAccuracy = 1.0\n",
      "\tf1_score=1.0\n",
      "\tPrecision=1.0\n",
      "\t\\Recall=1.0\n",
      "training scores:\n",
      "\tAccuracy = 0.864\n",
      "\tf1_score=0.737\n",
      "\tPrecision=0.756\n",
      "\t\\Recall=0.72\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred = rfc.predict(vectorized_x_train_smote)\n",
    "y_test_pred = rfc.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90292867-a273-4287-a5c6-8193610b5c17",
   "metadata": {},
   "source": [
    "### Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8bbe4be4-2335-4c1e-94c3-dedaecd8ebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training scores:\n",
      "\tAccuracy = 0.977\n",
      "\tf1_score=0.977\n",
      "\tPrecision=0.96\n",
      "\t\\Recall=0.996\n",
      "training scores:\n",
      "\tAccuracy = 0.878\n",
      "\tf1_score=0.78\n",
      "\tPrecision=0.747\n",
      "\t\\Recall=0.815\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(vectorized_x_train_smote,y_train_smote)\n",
    "\n",
    "y_train_pred = svm.predict(vectorized_x_train_smote)\n",
    "y_test_pred = svm.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote,y_train_pred)\n",
    "validation_scores(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fa2c7664-38c0-4fb0-af4c-9c301761d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../static/model/model.pickle','wb') as file:\n",
    "    pickle.dump(lr,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4a33d-202f-4cd2-bc79-50d293b5cfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
